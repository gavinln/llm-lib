# llamaindex samples

[LlamaIndex][100] is a Python library for working with LLM applications.

[100]: https://github.com/run-llama/llama_index

## Links

https://docs.llamaindex.ai/en/stable/

### Vector stores

#### Simple vector store

https://docs.llamaindex.ai/en/stable/examples/vector_stores/SimpleIndexDemo/

#### Simple vector store - async

https://docs.llamaindex.ai/en/stable/examples/vector_stores/AsyncIndexCreationDemo/

#### Simple vector store - MMR

https://docs.llamaindex.ai/en/stable/examples/vector_stores/SimpleIndexDemoMMR/

#### Faiss Vector Store

https://docs.llamaindex.ai/en/stable/examples/vector_stores/FaissIndexDemo/

#### DocArray InMemory Vector Store

https://docs.llamaindex.ai/en/stable/examples/vector_stores/DocArrayInMemoryIndexDemo/

#### DocArray Hnsw Vector Store

https://docs.llamaindex.ai/en/stable/examples/vector_stores/DocArrayHnswIndexDemo/

#### Auto-Retrieval from a Vector Database

https://docs.llamaindex.ai/en/stable/examples/vector_stores/chroma_auto_retriever/

## LLamaindex components

1. Loading data - ingestion
2. Indexing and Embedding
3. Storing
4. Querying
5. Tracing and debugging
6. Evaluating
